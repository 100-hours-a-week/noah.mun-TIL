# Section 3

---

## 가용성(Availability), 시스템 이중화

<aside>
📖

대규모 트래픽을 처리하기 위해 시스템을 고도화해야 한다. 고도화 할 때 성능 (Throughput, Latency)만 신경쓰면 안 된다. ‘가용성(Availability)’도 같이 신경쓰면서 시스템을 고도화해야 한다.

</aside>

### ✅ 가용성(Availiability)

**가용성(Availiability)**이란 **시스템이 서비스를 정상적으로 제공할 수 있는 가능성**을 말한다. 서비스에 장애가 발생할 가능성이 극히 작은 시스템을 가용성이 높은 시스템이라고 할 수 있다. 반대로 서비스가 다운되는 시간이 긴 시스템을 가용성이 낮은 시스템이라고 한다.

가용성이 높고 낮음은 서비스의 정상 가동률(%)로 표시된다. 가용성 99.99%는 99.99% 시간을 정상적으로 이용 가능한 시스템을 말한다. 다시 말하면 1년에 53분 정도는 서비스가 다운된다는 소리다.

***[높은 가용성을 가진 시스템 설계 방법]***

가용성을 높이기 위해서는 서비스 사용 가능 불가능 시간을 최대한 발생시키지 않게 하고 설령 발생하더라도 그 시간을 짧게 만들어야 한다. 다운 타임을 줄이는 데 가장 중요한 설계 방법 중 하나가 **시스템 이중화**이다.

### ✅ 시스템 이중화

<aside>
📖

시스템 이중화는 시스템의 일부분을 사용할 수 없게 되어도 다른 시스템을 이용하여 서비스를 계속 이용할 수 있게 만드는 걸 의미한다.

예를 들어, 도시를 연결하는 도로가 하나가 아닌 두 개가 있다면 둘 중 하나의 도로에서 사고가 발생하더라도 다른 도로를 이용하여 수송할 수 있다. 또한, 두 개의 도로가 존재함으로써 공사 중에도 정상적으로 수송을 할 수 있다.

</aside>

![3-1.png](/images/3-1.png)

시스템 이중화에서는 아래와 같이 설계할 수 있다. 이와 같이 이중화 설계를 하면 다운 타임을 줄일 수 있게 된다.

즉, 서비스의 가용성을 높일 수 있게 된다.

![3-2.png](/images/3-2.png)

### ✅ 수평적 확장

특정 시스템 성능을 올리기 위해 **시스템 개수를 늘리는 것**을 수평적 확장이라고 한다.

위 그림과 같은 경우를 수평적 확장이라고 한다.

**[장점]**

- 시스템 이중화 → 가용성 증가
- 확장에 제한이 없음 (무한대로 만들면 됨)
- 서버 축소/확장이 쉬움

**[단점]**

- 여러 대의 서버를 한 서버처럼 사용하기 위한 추가 작업이 필요함
    - ex) 로드 밸런서

### ✅ 수직적 확장

특정 시스템 성능을 올리기 위해 시스템 개수 변경 없이 **시스템의 스펙(CPU, 메모리)을 업그레이드** 하는 방식

![3-3.png](/images/3-3.png)

**[장점]**

- 여러 대의 서버를 한 서버처럼 사용하기 위한 추가 작업이 필요 없음
    - 심플하게 인프라 구성을 할 수 있어 관리 비용이 적게 듦

**[단점]**

- 시스템 이중화 ❌ → 가용성 감소
- 시스템 스펙에는 제한이 있으므로 확장에 제한이 생김
- 서버 축소/확장을 할 때마다 서비스 중단(다운 타임)이 불가피함 → 가용성 감소

### ✅ 캐싱(Caching)

캐싱(Caching)이란 데이터를 더 빠르게 엑세스할 수 있는 곳에 임시로 저장하는 방식을 의미

![3-4.png](/images/3-4.png)

## 트래픽 증가에 따른 시스템 설계 및 확장 방법

<aside>
📖

부하 테스트를 하면서 목표로 설정해놓은 Throughput, Latency를 달성하기 위해 성능 개선을 해야한다. 병목 지점이 어디서 발생하느냐에 따라 성능 개선의 방법이 달라진다. 이 방법에 대해 대략적으로 알아놓아야 성능 개선을 수월하게 할 수 있다.

</aside>

### ✅ 가장 간단한 형태

![3-5.png](/images/3-5.png)

EC2 서버 한 대에 FE, BE, DB에 관련된 모든 프로그램들을 다 실행시키는 형태. 이형태의 장점은 하나의 서버에서 모든 리소스를 관리하기 때문에 관리 및 조작하기 쉽다. 또한 다양한 리소스를 쓰지 않기 때문에 비용이 적게 나온다.

하지만 위의 구성으로 실제 서비스를 운영하다보면 DB가 생각보다 많은 컴퓨팅 자원(CPU, 메모리, 디스크)을 사용한다. DB로 인해 웹 애플리케이션의 성능에 악영향을 줄 수 있기 때문에 별도의 서버를 분리하는 형식을 가진다.

### ✅ 데이터베이스 분리

![3-6.png](/images/3-6.png)

웹 서버와 데이터베이스를 분리한 인프라 구성이다. 위 인프라 구성에서 트래픽이 많아지면 정적 파일(이미지, 비디오, 웹 페이지 등)을 제공하는 부분에서 문제가 될 가능성이 크다. 일반적으로 정적 파일은 용량이 크기 때문에 컴퓨팅 자원을 많이 소모해서 서버에 과부하가 걸릴 가능성이 크다.

이를 해결하기 위해 정적 파일을 제공하는 서버만 별도로 분리하는 구성을 많이 가져간다 (CloudFront)

### ✅ 정적 파일 서버 분리

![3-7.png](/images/3-7.png)

S3를 활용해 정적 파일만을 제공하는 별도의 서버를 구축했다. 하지만 정적 파일은 용량이 큰 경우가 많기 때문에, 정적 파일을 제공받는 곳과 거리가 멀면 멀 수록 응답 속도가 오래 걸릴 수 밖에 없다.

이를 해결하기 위해 캐싱의 원리가 적용된 CDN을 활용해서 정적 파일 전송 속도를 향상시킨다.

### ✅ CDN 서버 활용

![3-8.png](/images/3-8.png)

이 구성에서 사용자 요청이 더 많아져서 EC2 인스턴스 한 대로 모든 요청을 처리할 수 없는 상황이 왔다고 가정하자. 이런 경우에는 EC2를 확장해야 한다.

확장 방식에는 수직적 확장과 수평적 확장의 방식이 있다. 하지만 시스템 이중화의 장점 때문에 EC2를 확장할 때는 수평적 확장의 방식을 많이 활용한다. (수직적 확장도 동시에 할 수 있음)

### ✅ 웹 애플리케이션 서버의 수평적 확장

![3-9.png](/images/3-9.png)

수평적 확장의 방식으로 웹 애플리케이션 서버(EC2)를 여러 대로 늘렸다. 하지만 사용자보고 여러 서버에 골고루 알아서 요청을 보내라고 할 수는 없다. 사용자의 요청을 여러 대의 웹 애플리케이션 서버에 골고루 전달하기 위한 장치가 필요하다. 그것이 로드 밸런서다.

### ✅ 로드 밸런서 도입

![3-10.png](/images/3-10.png)

로드 밸런서를 도입함으로써 수평적 확장을 한 여러 대의 EC2에 골고루 트래픽을 분산시킬 수 있게 되었다. 하지만 늘어난 웹 애플리케이션 서버에 따라 많은 수의 요청이 DB에 몰리게 된다.

DB에서 병목현상이 발생하면 DB 자체적으로 성능 개선할 수 있는 부분이 없는지를 먼저 고려한다. DB 자체적으로 성능 개선하는 방법에는 인덱스 활용, 역정규화, SQL문 튜닝 등이 있다. 이 방식으로 최대한 개선을 했는데도 DB에 병목 현상이 발생할 수도 있다. 그러면 수평적 확장의 방식을 고려해봐야 한다.

하지만 DB에 수평적 확장의 방식을 적용시키는 것은 어려운 점이 많다. 왜냐하면 기존에 저장되어 있는 데이터를 수평적 확장한 모든 DB에 복사해서 관리해야 한다. 데이터의 변경이 일어날 때마다 여러 대의 DB가 동기화 작업을 해야 한다. 동기화 작업은 DB 성능 저하를 유발하기 때문에 오히려 장점보다 단점이 더 큰 확장 방식이라고 판단했다. 이 때문에 DB는 수평적 확장보다는 수직적 확장의 방식으로 성능을 개선한다.

만약 DB를 최대한으로 수직적 확장 했음에도 추가적인 성능 개선이 필요하다면 읽기 전용 데이터베이스(Read Replica) 도입을 고려한다.

### ✅ 읽기 전용 데이터베이스(Read Replica) 도입

![3-11.png](/images/3-11.png)

DB를 수평적 확장 하지 못했던 이유는 데이터 동기화의 어려움 때문이었다. 하지만 실제 서비스에서 사용하는 쿼리 중 일부는 정밀한 데이터 동기화가 필요 없는 경우가 많다. 따라서 정밀한 데이터 동기화가 필요 없는 쿼리를 실행시킬 때 읽기 전용 데이터베이스를 많이 활용한다.

원래 하나의 데이터베이스가 모든 트래픽을 처리했어야만 했는데, 읽기 전용 데이터베이스를 도입함으로써 트래픽을 나눠서 처리할 수 있게 되었다.

이와 같은 방식으로 고사양의 데이터베이스를 사용하다보면 문제가 되는 게 비용이다. AWS의 다양한 서비스 중 RDS는 비싼 자원에 속한다. 그래서 비용 절감과 성능 향상을 위해 캐시 서버를 많이 활용한다.

### ✅ 캐시 서버 도입

![3-12.png](/images/3-12.png)

데이터를 조회할 때 항상 DB로 요청을 보냈다면, 캐시 서버를 도입함으로써 데이터 조회 요청의 응답을 DB 서버와 캐시 서버가 나눠서 처리할 수 있게 된다. 즉, 캐시 서버를 활용해서 DB 부하를 줄일 수 있다.

### ✅ 병목 지점에 따른 성능 개선 방법

> 이 정도의 시스템 설계 및 확장 방법만 알고 있어도 충분하다. 이번에는 병목 지점의 관점으로 성능 개선 방법을 정리해보자.
> 

1. **EC2(웹 애플리케이션 서버)가 병목 지점일 경우**
    1. 애플리케이션 로직에서 비효율적인 부분 개선하기
    2. 정적 파일 서버(S3, Cloudfront) 분리하기
    3. 로드밸런서(ELB)를 활용해 수평적 확장하기
    4. 수직적 확장하기
    
2. **RDS(데이터베이스 서버)가 병목 지점일 경우**
    1. 비효율적인 쿼리 개선하기 (인덱스 활용, SQL문 튜닝, 역정규화 등)
    2. 수직적 확장하기
    3. 읽기 전용 데이터베이스(Read Replica) 도입하기
    4. 캐시 서버 도입하기
